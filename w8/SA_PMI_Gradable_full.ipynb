{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ3_rIayDIRS"},"outputs":[],"source":["from __future__ import division\n","from collections import Counter # Counter() is a dict for counting\n","from collections import defaultdict\n","from numpy import mean\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYrUaYcQDIRc"},"outputs":[],"source":["# Sentiment values\n","sentiments = [\"positive\",\"neutral\",\"negative\"]\n","# List of positive words:\n","pos_words = [\"love\", \"great\", \"like\"]\n","# List of negative words:\n","neg_words = [\"hate\", \"bad\", \"annoy\"]\n","# List of target companies:\n","companies = [\"@virginamerica\", \"@united\", \"@southwestair\", \"@jetblue\", \"@usairways\", \"@americanair\"]\n","sentiment_words = pos_words+neg_words\n","\n","def s2id(sentiment):\n","    if sentiment == \"positive\":\n","        return 0\n","    elif sentiment == \"neutral\":\n","        return 1\n","    elif sentiment == \"negative\":\n","        return 2\n","    else:\n","        print(\"ERROR: bad value!!\")\n","        return -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHX8qypODIRd"},"outputs":[],"source":["#remove any counts from dictionary if it's below min_threshold or above max_treshold\n","#max_threshold is ignored if unset\n","def filter_occ_counts(counts, min_threshold, max_threshold=0):\n","    if (max_threshold > 0):\n","        return Counter({w : counts[w] for w in counts.keys() if counts[w] > min_threshold and counts[w] < max_threshold})\n","    else:\n","        return Counter({w : counts[w] for w in counts.keys() if counts[w] > min_threshold})\n","\n","#remove any co-occurence counts if below threshold\n","def filter_cooc_counts(co_counts, min_threshold):\n","     return {w: filter_occ_counts(co_counts[w], min_threshold) for w in co_counts.keys()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFsTDT1wDIRf","executionInfo":{"status":"ok","timestamp":1700824865746,"user_tz":0,"elapsed":336,"user":{"displayName":"Tomas Goldsack","userId":"02966222532301410239"}},"outputId":"040a27be-bfd5-41ae-aae2-301265d684c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["PMI check passed\n"]}],"source":["def PMI(c_xy, c_x, c_y, N):\n","    # Computes PMI(x, y) where\n","    # c_xy is the number of times x co-occurs with y\n","    # c_x is the number of times x occurs.\n","    # c_y is the number of times y occurs.\n","    # N is the number of observations.\n","    p_xy = c_xy/N\n","    p_x = c_x/N\n","    p_y = c_y/N\n","    pmi = np.log2( p_xy / (p_x*p_y) )\n","\n","    return pmi;\n","\n","#Do a simple error check using value computed by hand\n","if(PMI(2,4,3,12) != 1): # these numbers are from our y,z example\n","    print(\"Warning: PMI is incorrectly defined\")\n","else:\n","    print(\"PMI check passed\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RoyjxsP3DIRg"},"outputs":[],"source":["# Define the data structures used to store the counts:\n","occ_counts = Counter(); # Occurrence counts\n","cooc_counts = defaultdict(Counter); # Co-occurrence counts:\n","\n","#This will be indexed by target words. cooc_counts[companies] will contain\n","#a dictionary of co-occurrence counts of companies with each sentiment word.\n","df = pd.read_csv(\"Tweets_short.csv\", index_col=0)\n","df['text'] = df['text'].str.lower()\n","N = len(df)\n","print(\"Total number of tweets: {}\".format(len(df)))\n","#df['airline_sentiment']\n","#for tweet in df['text']:\n","for sentiment, tweet in df.itertuples(index=False):\n","    #print(\"{} {}\".format(sentiment,tweet))\n","    words = set(tweet.strip().split()) #remove duplicate words\n","    #print(words)\n","    for word in words:\n","        occ_counts[word] += 1 # Store occurence counts for all words\n","        # but only get co-occurrence counts for companies/sentiment word pairs\n","        if word in companies:\n","            for word2 in words:\n","                if word2 in sentiment_words:\n","                    cooc_counts[word][word2] += 1 # Store co-occurence counts\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTW-lthODIRh"},"outputs":[],"source":["#For a Counter c, c.most_common(n) returns a sorted list of the n most common\n","#items in c. If no n is given, it returns all items, sorted by decreasing frequency\n","print(\"Counts of positive words:\")\n","print(Counter({w : occ_counts[w] for w in pos_words}).most_common())\n","print(\"Counts of negative words:\")\n","print(Counter({w : occ_counts[w] for w in neg_words}).most_common())\n","print(\"Counts of target words:\")\n","print(Counter({w : occ_counts[w] for w in companies}).most_common())\n","print()\n","for company in companies:\n","    print(\"{} cooc counts: {}\".format(company, cooc_counts[company].most_common()))\n","\n","\n","#Do some simple error checks using value computed beforehand\n","print()\n","if occ_counts['like'] != 411:\n","    print(\"Warning: counting is incorrectly defined\")\n","elif occ_counts['hate'] != 37:\n","    print(\"Warning: counting is incorrectly defined\")\n","elif cooc_counts['@jetblue']['love'] != 50:\n","    print(\"Warning: counting is incorrectly defined\")\n","elif cooc_counts['@usairways']['bad'] != 34:\n","    print(\"Warning: counting is incorrectly defined\")\n","else:\n","    print(\"Counting check passed\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOMD9FUYDIRi"},"outputs":[],"source":["#filter out co-occurrences with too few counts if you want\n","#cooc_counts = filter_cooc_counts(cooc_counts, 2)\n","\n","for company in companies:\n","    company_count = occ_counts[company]\n","    posPMIs = []\n","    negPMIs = []\n","    # compute PMI between target and each positive word, and\n","    # add it to the list of positive sentiment PMI values\n","    for pos in pos_words:\n","        if(pos in cooc_counts[company]): # Check if the words actually co-occur\n","            # If so, compute PMI and append to the list\n","            posPMIs.append(PMI(cooc_counts[company][pos],company_count,occ_counts[pos],N));\n","    # same for negative sentiment words\n","    for neg in neg_words:\n","        if(neg in cooc_counts[company]):\n","            negPMIs.append(PMI(cooc_counts[company][neg],company_count,occ_counts[neg],N));\n","    #uncomment the following line when posPMIs and negPMIs are no longer empty.\n","    print(\"{:14s}: {:5.2f} (pos), {:5.2f} (neg)\".format((company).ljust(12), mean(posPMIs), mean(negPMIs)))\n"]},{"cell_type":"markdown","metadata":{"id":"C7UBfWAGDIRm"},"source":["# Gradable method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3SYTzTkDIRr"},"outputs":[],"source":["valence = pd.read_csv(\"valence_lexicon_small.tsv\", sep='\\t', index_col=0)['Valence'].to_dict()\n","\n","negation_words = []\n","with open(\"negation_words.txt\", 'rt') as fd:\n","    negation_words = [line.rstrip() for line in fd]\n","#print(negation_words)\n","\n","#See https://en.wiktionary.org/wiki/Category:English_degree_adverbs\n","strengthen_words = pd.read_csv(\"strengthen_words.tsv\", sep='\\t', index_col=0)['score'].to_dict()\n","#print(strengthen_words)\n","\n","weaken_words = pd.read_csv(\"weaken_words.tsv\", sep='\\t', index_col=0)['score'].to_dict()\n","#print(weaken_words)\n","\n","exclamation_words = {'!':0.1, \"!!\":0.2, \"!!!\":0.3}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pCjl4GeDIRs"},"outputs":[],"source":["def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum()\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.grid(False)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dx4Y3cdADIRt"},"outputs":[],"source":["# Gradable method\n","\n","# This threshold is used to distinguish between negative / neutral / positive tweets\n","# negative < -threshold <= neutral <= +threshold < positive\n","threshold = 0.05\n","cm = np.zeros((3,3))\n","\n","sentiment_predictions = []\n","\n","for sentiment, tweet in df.itertuples(index=False):\n","    tweet_valence = 0\n","    words = tweet.strip().split()\n","    for w in words:\n","        if w in valence:\n","            tweet_valence += valence[w]\n","        if w in negation_words:\n","            tweet_valence *= -0.8\n","        if w in exclamation_words:\n","            tweet_valence += exclamation_words[w]\n","        if w in strengthen_words:\n","            tweet_valence += strengthen_words[w]\n","        if w in weaken_words:\n","            tweet_valence += weaken_words[w]\n","\n","    if tweet_valence > threshold:\n","        sentiment_pred = 'positive'\n","        sentiment_predictions.append('positive')\n","    elif tweet_valence < -threshold:\n","        sentiment_pred = 'negative'\n","        sentiment_predictions.append('negative')\n","    else: # tweet_valence == 0:\n","        sentiment_pred = 'neutral'\n","        sentiment_predictions.append('neutral')\n","\n","    cm[s2id(sentiment)][s2id(sentiment_pred)] += 1\n","\n","\n","print(\"######### TH = {}\".format(threshold))\n","print(cm)\n","precision = np.trace(cm) / np.sum(cm)\n","print(precision)\n","\n","plot_confusion_matrix(cm           = cm,\n","                      normalize    = False,\n","                      target_names = sentiments,\n","                      title        = \"Confusion Matrix\")\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}